---
title: "Stats Homework 4"
author: "2015-26042 Hyunghun Cho"
date: "Tuesday, October 04, 2016"
output: pdf_document
---

# 5.6 Exercises

## 5.5 Working backwards I

Based on the formulars, T df is Marginal Error(ME) over SE and SE is s over sqrt(n). Therefore, S is calculated with (ME * sqrt(n) / T df)
T df can be obtained from t distribution probability table or qt() function when degree of freedom is (n-1).
Finally, s can be calculated as below:

```{r}
mu.x <- (18.985 + 21.015)/2
margin.err <- mu.x - 18.985
n <- 36
df <- n - 1
conf <- .975 # 95% confidence level
t.df <- qt(conf, df=df)
s.x <- margin.err * sqrt(n) / t.df
print(s.x)

```

## 5.6 Working backwards II
As above, sample mean, ME and s.x can be calcuated as below: 
```{r}
conf <- 0.95 # 09% confidence level
n <- 25
df <- n - 1
mu.x <- (65 + 77) / 2
print(mu.x)
margin.err <- mu.x - 65
print(margin.err)
t.df <- qt(conf, df=df)
s.x <- margin.err * sqrt(n) / t.df
print(s.x)
```

## 5.7 Sleep habits of New Yorkers
```{r}
n <- 25 # number of sample 
mu.x <- 7.73
s.x <- 0.77
min <- 6.17
max <- 9.78
null <- 8
```

### (a) 
H.0: mu = 8, New Yorkers sleep 8 hours / night on average.
H.a : mu < 8, New Yorkers sleep less than 8 hours / night on average.

### (b) 
Independence: sample is random and from less than 10% of population. I will use *t-distribution* because sample is small. skew is acceptable because its difference is just 0.49. degree of freedom and T are as below:
```{r}
skew.right <- mu.x - min
skew.left <- mu.x - max
skew.diff <- abs(abs(skew.right) - abs(skew.left))
df <- n - 1
print (df)
SE <- s.x / sqrt(n)
t.df <- (mu.x - null) / SE
print (t.df)
```

### (c)
p-value lie between 0.025 and 0.05 if New Yorkers sleep less than 7.73 hours per night on average. 
```{r, echo=FALSE}
p.val <- pt(t.df, df=df, lower.tail = FALSE)
print (p.val)
```

### (d) p value is less than 0.05. Therefore, null hypothesis is rejected.  Strong evidence is supported by the data that New Yorkers sleep less than 8 hours.   

### (e) No, T value for 90% confidence interval is larger than T df. Therefore, null hypothesis is rejected also. 
```{r}
t <- qt(.9, df=df, lower.tail = FALSE)
print(t)

```

## 5.11 Play the piano

```{r}
n <- 20
mu.x <- 4.6
s.x <- 2.2
df <- n - 1
```

### (a) 
H.0: mu = 5, the average child takes 5 years of piano lessons
H.a: mu.x > 5, the average child takes at least 5 years of piano lessons.

p value is about 0.21. It is bigger than 0.05. Therefore null hypothesis can not be rejected. I have no strong evidence to reject Georgianna's claim.

```{r}
null <- 5
SE <- s.x / sqrt(n)
t.df <- (mu.x - null) / SE
print (t.df)
p.val <- 1- pt(t.df, df=df, lower.tail = FALSE)
print (p.val)
```

### (b)
The 95% confidence iterval is as below. Therefore we are 95% confident that the average number of years a child takes piano lessons in this city is 3.57 to 5.63 years.
```{r}
t.critical <- qt(.025, df=df, lower.tail = FALSE)
conf <- c(mu.x - (t.critical * SE) ,  mu.x + (t.critical * SE)) 
print(conf)
```
### (c)
Yes, I agree that I did not reject the null hypothesis and the null value is in t-interval


## 5.17 Paired or not? I
### (a) 
Paired if the students at the begining and at the end of the semester are same.  

### (b) 
Not paired if the subjects were randomly sampled

### (c) 
Paired if the group of patient is same at the beginning and after 2 years.

### (d) 
Paired if the subjects are same at begining and at end.

## 5.18 Paired or not? II

### (a) 
Not paired even if the trend of stocks between Intel's and Southwest Airline's look related.

### (b) 
Paired if the randomly sampled items are identical both Target store and Walmart.

### (c) 
Not paired if the randomly sampled students are not identical in each high school.

## 5.20 High school and Beyond I
### (a) 
No, there isn't. The box plot depicts no significant differences between reading and writing.

### (b) 
No, if randomly sampled student are identical in both reading and writing.

### (c) 
H.0: mu.diff = 0, there is no differences in both reading and writing scores of random sampled 200 students.  
H.a : mu.diff <> 0, there is differences in both reading and writing scores of random sampled 200 students.

### (d)
Independence: sample is random and from less than 10% of population. skew is acceptable.

### (e) 
No, the p-value is larger than 0.05 as below. Therefore null hypothesis can not be rejected. I have no strong evidence to convince evidence of a difference between the average scores on two exams.

```{r}
mu.x <- -0.545
n <- 200
df <- n - 1
s.x <- 8.887
null <- 0
SE <- s.x / sqrt(n)
t.df <- (mu.x - null) / SE
p.val <- pt(t.df, df=df, lower.tail = FALSE)
print (p.val)

```

### (f)
Type 2 Error, since we may have incorrectly failed to reject H.0
There may be a difference on two exams, but I was unable to detect it.

### (g)
Yes, since I failed to reject H.0 which has a null value of 0.

## 5.22 High school and Beyond II
### (a)
The 95% confidence iterval is as below. 
```{r}
t.critical <- qt(.025, df=df, lower.tail = FALSE)
conf <- c(mu.x - (t.critical * SE) ,  mu.x + (t.critical * SE)) 
print(conf)
```
### (b)
I am 95% confident that the average differences on two exam is between -1.78 and 0.69.

### (c)
No, since 0 is included in the interval

## 5.32 Fuel efficiency of manual and automatic cars I
Yes, the p-value is smaller than 0.01 as below. Therefore null hypothesis can be rejected. I have a strong evidence to convince evidence of a difference between the average fuel efficiency of cars with manual and automatic transmissions.

```{r}
N.a <- 26
N.b <- 26
M.a <- 16.12
M.b <- 19.85
SD.a <- 3.58
SD.b <- 4.51
diff.mean <- M.a-M.b
SS.a <- SD.a^2 * (N.a - 1)
SS.b <- SD.b^2 * (N.b - 1)
df <- (N.a - 1) + (N.b - 1)
# by null hypothesis, mu.source.a and mu.source.b is identical
mu.mm <- 0

var.source <- (SS.a + SS.b) / ((N.a - 1) + (N.b - 1))
est_sigma.mm <- sqrt(var.source/N.a + var.source/N.b)
t <- (M.a - M.b) / est_sigma.mm
print (t)
p.val <- 1- pt(t, df=df, lower.tail = FALSE)
print (p.val)
```

## 5.34 Fuel efficiency of manual and automatic cars II
I am 98% confident that the differences between average highway mileage of  manual and automatic cars is not between -2.05 and 0.96.
```{r}
N.a <- 26
N.b <- 26
M.a <- 22.92
M.b <- 27.88
SD.a <- 5.29
SD.b <- 5.01
diff.mean <- M.a-M.b
SS.a <- SD.a^2 * (N.a - 1)
SS.b <- SD.b^2 * (N.b - 1)
df <- (N.a - 1) + (N.b - 1)
# by null hypothesis, mu.source.a and mu.source.b is identical
mu.mm <- 0

var.source <- (SS.a + SS.b) / ((N.a - 1) + (N.b - 1))
est_sigma.mm <- sqrt(var.source/N.a + var.source/N.b)
t <- (M.a - M.b) / est_sigma.mm
print (t)

t.critical <- qt(.01, df=df, lower.tail = FALSE) # 98% confidence interval
conf <- c(mu.x - (t.critical * SE) ,  mu.x + (t.critical * SE)) 
print(conf)
```

# music

```{r}
filename <- 'music.csv'
music <- read.csv(filename, header=TRUE, sep=",")
group.a <- subset(music, Group == 'A')
group.b <- subset(music, Group == 'B')
X.a <- group.a$Completed
X.b <- group.b$Completed
N.a <- length(X.a)
N.b <- length(X.b)
M.a <- mean(group.a$Completed)
M.b <- mean(group.b$Completed)
SS.a <- sum( (X.a - M.a)^2)
SS.b <- sum( (X.b - M.b)^2)
diff.mean <- M.a-M.b
#mu.m <- mu.source
#mu.mm <- mu.source.a - mu.source.b

# by null hypothesis, mu.source.a and mu.source.b is identical
mu.mm <- 0
#sigma.mm <- sqrt(sigma.source^2 / N.a + sigma.source^2 / N.b)
# z <- (M.x.a - M.x.b) / sigma.mm
df <- (N.a - 1) + (N.b - 1)

var.source <- (SS.a + SS.b) / ((N.a - 1) + (N.b - 1))
est_sigma.mm <- sqrt(var.source/N.a + var.source/N.b)
t <- (M.a - M.b) / est_sigma.mm
print (t)
# 95% confindence interval if 
qt(c(.05, .95), df=df)


# 95% confidence interval if H0 is that mu.source.b is either greater or lesser than mu.source.a
qt(c(.025, .975), df=df)

var.test(X.a, X.b)
```

# smoker

```{r, echo=FALSE}
nonsmokers <- c(18, 22, 21, 17, 20, 17, 23, 20, 22, 21)
smokers <- c(16, 20, 14, 21, 20, 18, 13, 15, 17, 21)

plot(density(nonsmokers))
plot(density(smokers))
boxplot(nonsmokers,smokers, names=c("nonsmokers","smokers"))

t.test(nonsmokers, smokers, var.equal = TRUE)
```

# shoe

```{r}
filename <- 'shoes.csv'
shoes <- read.csv(filename, header=TRUE, sep=",")
shoes.diff <- shoes$shoesOn - shoes$shoesOff
N.diff <- length(shoes.diff)
M.diff <- mean(shoes.diff)
SS.diff <- sum( (shoes.diff - M.diff)^2)
var.source <- (SS.diff) / (N.diff - 1)
est_sigma.mm <- sqrt(var.source/N.diff)
t <- (M.diff - 0) / est_sigma.mm
t.test(shoes.diff, mu=0)
```
